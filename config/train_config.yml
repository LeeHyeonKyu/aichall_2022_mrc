DIRECTORY:
  dataset: dataset

AUGMENTATION:
  random_masking: True
  question_shuffle_aug: True
  pororo_aug: True
  gpt_aug: True
  
TRAINER :
  debug: False
  tokenizer: AutoTokenizer
  model: QASDS # AutoModelForQuestionAnswering # Conv # QAConv #SDS #QASDS
  pretrained: klue/roberta-large # klue/roberta-base #large  #xlm-roberta-large #tau/splinter-base
  optimizer: adamp
  learning_rate: 1.0e-5
  loss: mix #mix #joint #crossentropy
  scheduler: warmupcosine
  metric:
    - accuracy
  n_epochs: 50
  early_stopping_target: val_loss
  early_stopping_patience: 5
  early_stopping_mode: min
  amp: True
  gpu: 0
  seed: 42
  grad_accum: 16
  KFold: 5

DATALOADER:
  batch_size: 4
  num_workers: 0
  shuffle: True
  pin_memory: False
  drop_last: False

LOGGER:
  wandb:
    use: True
    username: team-ikyo
    project_serial: aichallenge_2022
  logging_interval: 200
  plot:
    - loss
    - accuracy